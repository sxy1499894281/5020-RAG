data:
  raw: ./data/arxiv-metadata-oai-snapshot.json
  clean: ./data/clean.jsonl

bm25:
  index_path: ./data/bm25.idx

dense:
  db: ./data/chroma
  provider: chroma
  model: BAAI/bge-small-en-v1.5
  collection: arxiv

retrieval:
  mode: hybrid
  topk: 5
  alpha: 0.5           # 初始固定 alpha
  dynamic_alpha: false  # 是否启用自适应 alpha
  expansion:
    enable: true      # 查询扩展总开关
    prf:
      enable: true
      m_docs: 5
      top_terms: 10
    llm:
      enable: true    # 初期可关掉 LLM 改写
      n_variants: 3

rerank:
  enable: true
  model: BAAI/bge-reranker-base
  topn: 50
  batch_size: 16

rag:
  use_evidence_snippets: false
  evidence:
    per_doc: 2
    max_total: 10
    method: bm25       # 句级打分方式：bm25 | embedding

generation:
  provider: openai           # mock | openai | ollama（或其他 OpenAI 兼容服务）
  model:  Qwen 8B      # 示例：OpenAI 官方模型名，可按需要修改
  max_tokens: 512

  # 使用真实 LLM 时的说明（代码里会从环境变量读取）：
  # - OPENAI_API_KEY  : 必填，你的 API Key
  # - OPENAI_BASE_URL : 选填，OpenAI 兼容服务地址
  #   - 官方 OpenAI 可设为: https://api.openai.com/v1
  #   - 其他厂商按其文档填写

category:
  enable_filter: false
  allowed_prefixes: ["cs."]
  enable_boost: false
  boost_factor: 0.1

runtime:
  max_context_chars: 6000
  seed: 42
  latency_budget_ms: 1000
